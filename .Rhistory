# checking for duplicated birthdays in one 50 person group
n <- 50
bdays <- sample(1:365, n, replace = TRUE) # generate n random birthdays
any(duplicated(bdays)) # check if any birthdays duplicated
# Monte Carlo simulation
B <- 10000
results <- replicate(B, {
bdays <- sample(1:365, n, replace = TRUE)
any(duplicated(bdays))
})
mean(results)
ls
ls()
rm(B)
rn("n")
rm(list=c("n"))
rm(list=ls())
x <- 1:10
sqrt(x)
y <- 1:10
x*y
compute_prob <- function(n, B = 10000) {
same_day <- replicate(B, {
bdays <- sample(1:365, n, replace = TRUE)
any(duplicated(bdays))
})
mean(same_day)
}
n <- seq(1, 60)
compute_prob(x)
prob <- sapply(x, compute_prob)
plot(x,prob)
prob <- sapply(n, compute_prob)    # element-wise application of compute_prob to n
plot(n, prob)
seq(365, 365-10)
seq(365, 365-10)/10
# function for computing exact probability of shared birthdays for any n
exact_prob <- function(n){
prob_unique <- seq(365, 365-n+1)/365   # vector of fractions for mult. rule
1 - prod(prob_unique)    # calculate prob of no shared birthdays and subtract from 1
}
# applying function element-wise to vector of n values
eprob <- sapply(n, exact_prob)
# plotting Monte Carlo results and exact probabilities on same graph
plot(n, prob)    # plot Monte Carlo results
lines(n, eprob, col = "red")    # add line for exact prob
(c(35, 88, 42, 84, 81, 30)-32)*5/9
rm(list=ls())
all_cases <- sum(esoph$ncases)
all_controls <- sum(esoph$ncontrols)
summary(esoph)
# 5A
esoph %>%
filter(alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
#Libraries
library(gtools)
library(tidyverse)
# 5A
esoph %>%
filter(alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
summary(esoph)
# 5B For cases, prob in highest tobacco group
esoph %>%
filter(tobgp == "30+") %>%
pull(ncases) %>%
sum()/all_cases
esoph %>% filter(alcgp == "120+")
esoph %>% filter(alcgp == "120+") %>% pull(ncases) %>%sum()
summary(esoph)
# 5C For cases, prob highest tobacco & highest alcohol
esoph %>%
filter(tobgp == "30+" && alcgp == "120+")
# 5C For cases, prob highest tobacco & highest alcohol
esoph %>%
filter(tobgp == "30+" & alcgp == "120+")
# 5C For cases, prob highest tobacco & highest alcohol
esoph %>%
filter(tobgp == "30+" & alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
# 5D For cases, prob highest tobacco or highest alcohol
esoph %>%
filter(tobgp == "30+" | alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
#6A
p_control_high_alc <- esoph %>%
filter(alcgp == "120+") %>%
pull(ncontrols) %>%
sum()/all_controls
p_control_high_alc
# 5A For cases, prob in highest alcohol group
esoph %>%
filter(alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
# 5A For cases, prob in highest alcohol group
p_case_high_alc <- esoph %>%
filter(alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
# 5B For cases, prob in highest tobacco group
p_case_high_tob <- esoph %>%
filter(tobgp == "30+") %>%
pull(ncases) %>%
sum()/all_cases
p_case_high_tob
# 5B For cases, prob in highest tobacco group
p_case_high_tob <- esoph %>%
filter(tobgp == "30+") %>%
pull(ncases) %>%
sum()/all_cases
# 5C For cases, prob highest tobacco & highest alcohol
p_case_high_alc_tob <- esoph %>%
filter(tobgp == "30+" & alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
# 5D For cases, prob highest tobacco or highest alcohol
p_case_either_highest <- esoph %>%
filter(tobgp == "30+" | alcgp == "120+") %>%
pull(ncases) %>%
sum()/all_cases
# 6B How many times more likely cases than controls to be in highest alcoholic group
p_case_high_alc/p_control_high_alc
# 6C For control, prob highest tobacco
p_control_high_tob <- esoph %>%
filter(tobgp == "30+") %>%
pull(ncontrols) %>%
sum()/all_controls
p_control_high_tob
# 5C For control, prob highest tobacco & highest alcohol
p_control_high_alc_tob <- esoph %>%
filter(tobgp == "30+" & alcgp == "120+") %>%
pull(ncontrols) %>%
sum()/all_controls
p_control_high_alc_tob
p_control_either_highest <- p_control_high_alc + p_control_high_tob - p_control_high_alc_tob
p_control_either_highest
# 6F
p_case_either_highest/p_control_either_highest
rm(list=ls())
# 4A
esoph %>%
filter(alcgp == "120+") %>%
summarize(ncases = sum(ncases), ncontrols = sum(ncontrols)) %>%
mutate(p_case = ncases / (ncases + ncontrols)) %>%
pull(p_case)
?tibble
set.seed(16, sample.kind="Rounding")
sample(4:10)
sample(4:10)
set.seed(16, sample.kind="Rounding")
sample(4:10)
set.seed(16, sample.kind="Rounding")
sample(4:10)
set.seed(16, sample.kind="Rounding")
sample(4:10)
#Monte Carlo Simulation
B <- 10000
set.seed(16, sample.kind="Rounding")
# Generate Scores
act_scores <- rnorm(10000, 20.9, 5.7)
rm(list=ls())
set.seed(16, sample.kind="Rounding")
# Generate Scores
act_scores <- rnorm(10000, 20.9, 5.7)
set.seed(16, sample.kind="Rounding")
# Generate Scores
act_scores <- rnorm(10000, 20.9, 5.7)
# 1a
mean(act_scores)
# 1b
sd(act_scores)
#1c
act_perf_scores <- nrow(act_scores>=36)
act_scores >= 36
#1c
act_perf_scores <- sum(act_scores>=36)
act_perf_scores
#1c
sum(act_scores>=36)
#1d
mean(act_scores > 30)
rm(act_perf_scores)
#1e
mean(act_scores <= 10)
# 2
x = 1:36
seq(4)
seq(1,4,2)
seq(1,4,2)
f_x <- dnorm(x,20.9,5.7)
f_x <- dnorm(x,20.9,5.7)
plot(x, f_x)
# 3
(act_scores - mean(act_scores)) / sd(act_scores)
act_scores
# 3
z_act_scores <- (act_scores - mean(act_scores)) / sd(act_scores)
View(table(act_scores,z_act_scores))
?table
View(c(act_scores, z_act_scores))
View(act_scores,z_act_scores)
View(data.frame(act_scores, z_act_scores))
# 3a
mean(z_act_scores > 2)
# 3
z_scores <- (act_scores - mean(act_scores)) / sd(act_scores)
rm(z_act_scores)
# 3b
mean(z_scores) + 2*sd(z_scores)
# 3b
2 * sd(act_scores) + mean(act_scores)
# 3c
qnorm(.975, mean(act_scores), sd(act_scores))
# 4
cdf_act <- function(p) {
mean(act_scores <= p)
}
probs <- replicate(1:36, cdf_act)
probs <- sapply(1:36, cdf_act)
plot(x = 1:36, probs)
View(probs)
mean(act_scores <= p)
# 4
cdf <- function(p) {
mean(act_scores <= p)
}
probs <- sapply(1:36, cdf)
rm(cdf_act())
rm(cdf_act)
# 4a
min(which(probs >= .95))
# 4b
qnorm(95, 20.9, 5.7)
# 4b
qnorm(.95, 20.9, 5.7)
?quantile
quantile(x <- rnorm(1001))
# 2
x = 1:36
quantile(x <- rnorm(1001))
# 2
x = 1:36
quantile(rnorm(1001))
rnorm(100)
sample_quantiles <- quantile(act_scores)
sample_quantiles
min(act_scores)
sample_quantiles <- quantile(act_scores, p)
# 4C
p <- seq(0.01, 0.99, 0.01)
sample_quantiles <- quantile(act_scores, p)
sample_quantiles
min(which(sample_quantiles >=26))
min(which(sample_quantiles >26))
max(which(sample_quantiles >26))
min(which(sample_quantiles >26))
min(which(sample_quantiles >=26))
max(which(sample_quantiles < 26))
names(max(which(sample_quantiles < 26)))
names(sample_quantiles[max(which(sample_quantiles < 26)]))
names(sample_quantiles[max(which(sample_quantiles < 26))])
# 4d
theoretical_quantiles <- sapply(p, quantile(mean=20.9, sd = 5.7))
# 4d
theoretical_quantiles <- qnorm(p, 20.9, 5.7)
theoretical_quantiles
qqplot(theoretical_quantiles, sample_quantiles)
qqplot(theoretical_quantiles, sample_quantiles) + geom_abline()
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
qqplot(theoretical_quantiles, sample_quantiles) + geom_abline()
qqplot(theoretical_quantiles, sample_quantiles) + geo_abline()
qqplot(theoretical_quantiles, sample_quantiles) + geom_abline()
qqplot(theoretical_quantiles, sample_quantiles)
qplot(theoretical_quantiles, sample_quantiles)
library(ggplot2)
qplot(theoretical_quantiles, sample_quantiles)
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
rm(list=ls())
p <- .04
loss_per_foreclosure <- -200000
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x*(1-p)
clc()
p <- .04
loss_per_foreclosure <- -200000
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x*(1-p) # Seems positive
### Calculating number of loans for desired probability of losing money
z <- qnorm(0.01)
?qnorm
l <- loss_per_foreclosure
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n    # number of loans required
n*(loss_per_foreclosure*p + x * (1-p))    # expected profit over n loans
B <- 10000
p <- 0.04
x <- 0.05 * 180000 # Because the interest rate needed was determined at 5%, hence 0.05
profit <- replicate(B, {
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-p, p), replace = TRUE)
sum(draws)
})
mean(profit)
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x*(1-p) # Still positive expected val
r <- 0.08
x <- r*180000
loss_per_foreclosure*p + x*(1-p) # Still positive expected val
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n    # number of loans required
0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
seq(-0.01, 0.01, length = 100)
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-new_p, new_p), replace = TRUE)
sum(draws)
})
mean(profit)    # expected profit
mean(profit < 0)    # probability of losing money
mean(profit < -10000000)    # probability of losing over $10 million
plot(profit)
hist(profit,bin=0.6)
hist(profit)
profit <- replicate(B, {
new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-new_p, new_p), replace = TRUE)
sum(draws)
})
hist(profit)
profit <- replicate(B, {
new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-new_p, new_p), replace = TRUE)
sum(draws)
})
profit <- replicate(B, {
new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-new_p, new_p), replace = TRUE)
sum(draws)
})
mean(profit)    # expected profit
mean(profit < 0)    # probability of losing money
mean(profit < -10000000)    # probability of losing over $10 million
hist(profit)
### Expected value with higher default rate and interest rate
p <- .04
loss_per_foreclosure <- -200000
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x*(1-p) # Still positive expected val
### Calculating number of loans for desired probability of losing money
z <- qnorm(0.01)
l <- loss_per_foreclosure
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n    # number of loans required
n*(loss_per_foreclosure*p + x * (1-p))    # expected profit over n loans
profit <- replicate(B, {
new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
draws <- sample( c(x, loss_per_foreclosure), n,
prob=c(1-new_p, new_p), replace = TRUE)
sum(draws)
})
mean(profit)    # expected profit
mean(profit < 0)    # probability of losing money
mean(profit < -10000000)    # probability of losing over $10 million
hist(profit)
10^6
10**6
hist(profit/10^6, title= "Profit in millions")
hist(profit/10^6, labels = "Profit in millions")
hist(profit/10^6, title = "Profit in millions")
?hist
hist(profit/10^6, xlab = "Profit in millions")
